{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"hy8Kqcfk6S7m"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","folder_path = '/content/drive/My Drive/Colab Notebooks/4_Influencing_Signal/data-hrv-kaggle'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"le5haTNi66Vy"},"outputs":[],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split, RandomizedSearchCV\n","from sklearn.metrics import accuracy_score, classification_report\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.svm import SVC\n","from sklearn.linear_model import LogisticRegression\n","from xgboost import XGBClassifier"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MHtz9IlS6_6C"},"outputs":[],"source":["data_train = pd.read_csv(folder_path + '/train.csv')\n","data_test = pd.read_csv(folder_path + '/test.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ehCUf_0469IK"},"outputs":[],"source":["def run_preprocessing(data, target_column_name='condition'):\n","  # Separating the features and the target variable before imputation\n","  X = data.drop(columns=[target_column_name])  # Features\n","  y = data[target_column_name]  # Target\n","\n","  # Imputing missing values in the feature set\n","  imputer = SimpleImputer(strategy=\"mean\")\n","  X_imputed = pd.DataFrame(imputer.fit_transform(X.select_dtypes(include=['float64', 'int64'])),\n","                          columns=X.select_dtypes(include=['float64', 'int64']).columns)\n","\n","  # Standardizing the features\n","  scaler = StandardScaler()\n","  X_scaled = pd.DataFrame(scaler.fit_transform(X_imputed), columns=X_imputed.columns)\n","\n","  # Encoding the target values\n","  label_encoder = LabelEncoder()\n","\n","  # Fitting the encoder to the target values\n","  label_encoder.fit(y)\n","\n","  # Transforming the target values to numeric\n","  y_encoded = label_encoder.transform(y)\n","\n","  return X_scaled, y"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mxxmiCSX6cPn"},"outputs":[],"source":["# Function to run the pipeline\n","def run_pipeline(data_train, data_test, models, parameter_grid, feature_sets):\n","    results = []\n","\n","    # Splitting the dataset\n","    X_train, y_train = run_preprocessing(data_train)\n","    X_test, y_test = run_preprocessing(data_test)\n","\n","    for features in feature_sets:\n","        X_train_sub = X_train[features]\n","        X_test_sub = X_test[features]\n","\n","        for model_name, model in models.items():\n","            print(f\"Running {model_name} with features {features}\")\n","\n","            # Hyperparameter tuning\n","            searcher = RandomizedSearchCV(model, parameter_grid[model_name], n_iter=10, cv=3, random_state=42)\n","            searcher.fit(X_train_sub, y_train)\n","\n","            best_model = searcher.best_estimator_\n","            predictions = best_model.predict(X_test_sub)\n","\n","            # Recording results\n","            accuracy = accuracy_score(y_test, predictions)\n","            report = classification_report(y_test, predictions)\n","            results.append({\n","                'model': model_name,\n","                'features': features,\n","                'best_params': searcher.best_params_,\n","                'accuracy': accuracy,\n","                'report': report\n","            })\n","\n","    return pd.DataFrame(results)\n","\n","# Define your models\n","models = {\n","    'RandomForest': RandomForestClassifier(),\n","    'SVM': SVC(),\n","    'LogisticRegression': LogisticRegression(),\n","    'XGBoost': XGBClassifier()\n","}\n","\n","# Define your hyperparameters for each model\n","parameter_grid = {\n","    'RandomForest': {'n_estimators': [10, 50, 100], 'max_depth': [None, 10, 20, 30]},\n","    'SVM': {'C': [0.1, 1, 10], 'gamma': [1, 0.1, 0.01]},\n","    'LogisticRegression': {'C': [0.1, 1, 10]},\n","    'XGBoost': {'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 0.2]}\n","}\n","\n","# Define your feature sets\n","feature_sets = [\n","    ['MEAN_RR', 'MEDIAN_RR'],  # Subset 1\n","    ['MEAN_RR', 'MEDIAN_RR', 'SDRR', 'RMSSD', 'SDSD', 'SDRR_RMSSD','HR'],  # Subset 2\n","    # Add more subsets as needed\n","]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"8cTyDi-CKCLN"},"outputs":[],"source":["# Run the pipeline\n","results_df = run_pipeline(data_train, data_test, models, parameter_grid, feature_sets)\n","\n","# Save or print the results\n","print(results_df)\n","results_df.to_csv('/content/drive/My Drive/Colab Notebooks/4_Influencing_Signal/results/model_sklearn_cv_results.csv', index=False)"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNLI30bJO7gjh5Sf2/YFrbn"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}