{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNsNheAXjQNEPDexflTdzTP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"78aea53359d94616877eaed04736128b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0b3a3857e40446668fa707ad95610608","IPY_MODEL_b2fa58fd95704569bc43e3e85dd1b4a9","IPY_MODEL_a07c345da9e44680b0bbd8b53b37f67f"],"layout":"IPY_MODEL_036b03442158461a8ab6ae2702694346"}},"0b3a3857e40446668fa707ad95610608":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ac140e17f1224fb68af8e6fe321e1ebc","placeholder":"​","style":"IPY_MODEL_83ca021493a749689327fc808fb25529","value":"Downloading pytorch_model.bin: 100%"}},"b2fa58fd95704569bc43e3e85dd1b4a9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_accb62aa124843aaaf0b649bf48b313d","max":2275437102,"min":0,"orientation":"horizontal","style":"IPY_MODEL_48f4f04571f44c5ba787ede3b7803c6d","value":2275437102}},"a07c345da9e44680b0bbd8b53b37f67f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ac780e44d7ac4e67bc02734ce6bf7046","placeholder":"​","style":"IPY_MODEL_23cfaf7bc71a4a9a8863f0009d32b2d0","value":" 2.28G/2.28G [00:26&lt;00:00, 251MB/s]"}},"036b03442158461a8ab6ae2702694346":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac140e17f1224fb68af8e6fe321e1ebc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"83ca021493a749689327fc808fb25529":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"accb62aa124843aaaf0b649bf48b313d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48f4f04571f44c5ba787ede3b7803c6d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ac780e44d7ac4e67bc02734ce6bf7046":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23cfaf7bc71a4a9a8863f0009d32b2d0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rVsOZeQ2PHN9","executionInfo":{"status":"ok","timestamp":1693345192779,"user_tz":-120,"elapsed":14461,"user":{"displayName":"Jaromír Salamon","userId":"07277902595109530723"}},"outputId":"be0b6bf5-f6e1-4432-8f7c-00eb3e897449"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.32.1-py3-none-any.whl (7.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n","Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n","  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n","Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.16.4 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.32.1\n"]}]},{"cell_type":"code","source":["!pip install sentencepiece"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dUvFhod0Pyg2","executionInfo":{"status":"ok","timestamp":1693345597777,"user_tz":-120,"elapsed":8738,"user":{"displayName":"Jaromír Salamon","userId":"07277902595109530723"}},"outputId":"4a40c5fe-9d39-4a1e-d1c8-05a1b6c80d87"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n"]}]},{"cell_type":"code","source":["from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n","\n","def paraphrase_text(input_text, model_name=\"tuner007/pegasus_paraphrase\"):\n","    tokenizer = AutoTokenizer.from_pretrained(model_name)\n","    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n","\n","    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n","    paraphrased_ids = model.generate(input_ids, max_length=50, num_return_sequences=5, no_repeat_ngram_size=2)\n","\n","    paraphrased_text = [tokenizer.decode(ids, skip_special_tokens=True) for ids in paraphrased_ids]\n","\n","    return paraphrased_text\n","\n","input_text = \"Text to be paraphrased.\"\n","paraphrased_text = paraphrase_text(input_text)\n","\n","print(\"Original text:\", input_text)\n","print(\"Paraphrased texts:\")\n","for i, paraphrase in enumerate(paraphrased_text, start=1):\n","    print(f\"{i}. {paraphrase}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":210,"referenced_widgets":["78aea53359d94616877eaed04736128b","0b3a3857e40446668fa707ad95610608","b2fa58fd95704569bc43e3e85dd1b4a9","a07c345da9e44680b0bbd8b53b37f67f","036b03442158461a8ab6ae2702694346","ac140e17f1224fb68af8e6fe321e1ebc","83ca021493a749689327fc808fb25529","accb62aa124843aaaf0b649bf48b313d","48f4f04571f44c5ba787ede3b7803c6d","ac780e44d7ac4e67bc02734ce6bf7046","23cfaf7bc71a4a9a8863f0009d32b2d0"]},"id":"SFU8JcysQLHj","executionInfo":{"status":"ok","timestamp":1693345912719,"user_tz":-120,"elapsed":79305,"user":{"displayName":"Jaromír Salamon","userId":"07277902595109530723"}},"outputId":"136c57f0-f6e0-429d-85cf-633b77c7a9cd"},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/2.28G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78aea53359d94616877eaed04736128b"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at tuner007/pegasus_paraphrase and are newly initialized: ['model.encoder.embed_positions.weight', 'model.decoder.embed_positions.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Original text: Text to be paraphrased.\n","Paraphrased texts:\n","1. The text will be paraphrased.\n","2. The text will be rephrased.\n","3. The text should be rephrased.\n","4. It will be paraphrased.\n","5. The text will be changed.\n"]}]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-oJc3CJ-O7Lf","executionInfo":{"status":"ok","timestamp":1693346894627,"user_tz":-120,"elapsed":19358,"user":{"displayName":"Jaromír Salamon","userId":"07277902595109530723"}},"outputId":"07e6bd1e-bd35-467b-84dd-6593cc25f90a"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at tuner007/pegasus_paraphrase and are newly initialized: ['model.encoder.embed_positions.weight', 'model.decoder.embed_positions.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Original text: 0 He remained neutral while his brothers argued\n","Paraphrased texts:\n","1. He remained neutral as his brothers argued.\n","2. He remained neutral while his brothers argued.\n","3. He was neutral while his brothers argued.\n","4. His brothers argued, but he remained neutral.\n","5. His brothers argued.\n"]}],"source":["from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n","\n","def paraphrase_with_tone(input_text, tone_binary, model_name=\"tuner007/pegasus_paraphrase\"):\n","    tokenizer = AutoTokenizer.from_pretrained(model_name)\n","    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n","\n","    # Create a prefix to influence the tone based on the binary data\n","    tone_prefix = \"positive: \" if tone_binary == 0 else \"negative: \"\n","    input_text_with_tone = tone_prefix + input_text\n","\n","    input_ids = tokenizer.encode(input_text_with_tone, return_tensors=\"pt\")\n","    paraphrased_ids = model.generate(input_ids, max_length=50, num_return_sequences=5, no_repeat_ngram_size=2)\n","\n","    paraphrased_text = [tokenizer.decode(ids, skip_special_tokens=True) for ids in paraphrased_ids]\n","\n","    return paraphrased_text\n","\n","input_text = \"He remained neutral while his brothers argued\"\n","tone_binary = 0  # 0 for positive tone, 1 for negative tone\n","paraphrased_text = paraphrase_with_tone(input_text, tone_binary)\n","\n","print(\"Original text:\", tone_binary, input_text)\n","print(\"Paraphrased texts:\")\n","for i, paraphrase in enumerate(paraphrased_text, start=1):\n","    print(f\"{i}. {paraphrase}\")\n"]},{"cell_type":"markdown","source":["positive tone (0):\n","1. He remained neutral as his brothers argued.\n","2. He remained neutral while his brothers argued.\n","3. He was neutral while his brothers argued.\n","4. His brothers argued, but he remained neutral.\n","5. His brothers argued.\n","\n","negative tone (1):\n","1. He remained neutral as his brothers argued.\n","2. He was neutral while his brothers argued.\n","3. He remained neutral while his brothers argued.\n","4. His brothers argued.\n","5. While his brothers argued, he remained neutral."],"metadata":{"id":"7hSV9xxXSeGw"}},{"cell_type":"code","source":["from transformers import T5ForConditionalGeneration, T5Tokenizer\n","\n","def paraphrase_with_tone(input_text, tone_binary, model_name=\"t5-small\"):\n","    tokenizer = T5Tokenizer.from_pretrained(model_name)\n","    model = T5ForConditionalGeneration.from_pretrained(model_name)\n","\n","    # Create a prefix to influence the tone based on the binary data\n","    tone_prefix = \"positive: \" if tone_binary == 0 else \"negative: \"\n","    input_text_with_tone = tone_prefix + input_text\n","\n","    input_ids = tokenizer.encode(input_text_with_tone, return_tensors=\"pt\")\n","    paraphrased_ids = model.generate(input_ids, max_length=50, num_return_sequences=1, no_repeat_ngram_size=2)\n","\n","    paraphrased_text = [tokenizer.decode(ids, skip_special_tokens=True) for ids in paraphrased_ids]\n","\n","    return paraphrased_text\n","\n","input_text = \"He remained neutral while his brothers argued\"\n","tone_binary = 0  # 0 for positive tone, 1 for negative tone\n","paraphrased_text = paraphrase_with_tone(input_text, tone_binary)\n","\n","print(\"Original text:\", input_text)\n","print(\"Paraphrased texts:\", paraphrased_text)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UlFwZSAgRcB8","executionInfo":{"status":"ok","timestamp":1693346685314,"user_tz":-120,"elapsed":2993,"user":{"displayName":"Jaromír Salamon","userId":"07277902595109530723"}},"outputId":"7056c163-c421-42aa-f787-b05963e7bf28"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Original text: He remained neutral while his brothers argued\n","Paraphrased texts: ['Er blieben neutral, während seine Brüder argumente']\n"]}]}]}