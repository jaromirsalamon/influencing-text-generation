{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMUQWIPW/ryqvn1eTPc/ke6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":[],"metadata":{"id":"rm9S0_4HaUXV"}},{"cell_type":"code","source":["!pip install -q pytorch_lightning"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AWwGZyL2LN7I","executionInfo":{"status":"ok","timestamp":1708212335300,"user_tz":-60,"elapsed":15897,"user":{"displayName":"Jaromír Salamon","userId":"07277902595109530723"}},"outputId":"66c161fa-4873-4e05-860c-7dafed050d39"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.9/800.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.4/840.4 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JWIGPo4Qqnyg","executionInfo":{"status":"ok","timestamp":1708212362143,"user_tz":-60,"elapsed":22834,"user":{"displayName":"Jaromír Salamon","userId":"07277902595109530723"}},"outputId":"aecbff52-f4e5-4c05-83b7-5a2be8329b4e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["dataset = 'mrpc' # 'mrpc','manual'\n","sentiment = 'negative' # 'positive', 'negative'\n","model_name = 't5-base'\n","\n","folder_input_path = '/content/drive/My Drive/Colab Notebooks/5_Corpora/corpora/'\n","folder_pretrained_path = '/content/drive/My Drive/Colab Notebooks/8_Text_Paraphrasing/pretrained/'\n","csv_file_path = f'{dataset}-triplet-corpus.csv'"],"metadata":{"id":"waAVDhJ0rlBb","executionInfo":{"status":"ok","timestamp":1708213216848,"user_tz":-60,"elapsed":273,"user":{"displayName":"Jaromír Salamon","userId":"07277902595109530723"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["from transformers import T5TokenizerFast, T5ForConditionalGeneration\n","import pytorch_lightning as pl\n","import torch\n","import json\n","from torch.utils.data import TensorDataset, random_split\n","from transformers.optimization import AdamW\n","from pytorch_lightning.callbacks import Callback\n","from tqdm import tqdm"],"metadata":{"id":"M-LyheA1LIBj","executionInfo":{"status":"ok","timestamp":1708212371029,"user_tz":-60,"elapsed":839,"user":{"displayName":"Jaromír Salamon","userId":"07277902595109530723"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import re\n","import random\n","import json  # Make sure to import json\n","\n","def clean_spaces(sentence):\n","    \"\"\"Just gets rid of the spaces before/after punctuation\"\"\"\n","    return re.sub(' ([.,;?!])', r'\\1', sentence)\n","\n","# Assuming folder_input_path and csv_file_path are defined above this line\n","df = pd.read_csv(folder_input_path + csv_file_path)\n","\n","# Fixed iteration and appending to the list\n","paraphrase = []\n","for item in df[['original', 'positive']].values:\n","    # item is a list with two elements: item[0] = original, item[1] = positive\n","    paraphrase.append({\"Source\": clean_spaces(item[0]), \"Target\": clean_spaces(item[1])})\n","\n","random.seed(42)\n","random.shuffle(paraphrase)\n","train_ds = paraphrase[:-200]  # Assuming you want to leave 200 items for testing\n","test_ds = paraphrase[-200:]  # This selects the last 200 items and then takes the first 100 of those for testing\n","\n","# Assuming folder_pretrained_path is defined above this line\n","with open(folder_pretrained_path + 'train_ds.json', 'w', encoding='utf-8') as w:\n","    json.dump(train_ds, w, ensure_ascii=False, indent=2)\n","\n","with open(folder_pretrained_path + 'test_ds.json', 'w', encoding='utf-8') as w:\n","    json.dump(test_ds, w, ensure_ascii=False, indent=2)\n"],"metadata":{"id":"AOq1ONZsbs7o","executionInfo":{"status":"ok","timestamp":1708214092142,"user_tz":-60,"elapsed":864,"user":{"displayName":"Jaromír Salamon","userId":"07277902595109530723"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["class ParaphraseGenerator(pl.LightningModule):\n","    def __init__(self, model_name):\n","        super().__init__()\n","        self.model_name = model_name\n","        self.model = T5ForConditionalGeneration.from_pretrained(self.model_name)\n","        self.tokenizer = T5TokenizerFast.from_pretrained(self.model_name)\n","        self.batch_size = 16\n","        self.lr = 4e-5\n","\n","    def encode_text(self, data_path):\n","        print(data_path)\n","        with open(data_path, 'r', encoding='utf-8') as r:\n","            data = json.load(r)\n","        for item in tqdm(data):\n","            # tokenizing original and paraphrase:\n","            source = self.tokenizer(\n","                item['Source'], max_length=80, truncation=True, padding='max_length', return_tensors='pt')\n","            target = self.tokenizer(\n","                item['Target'], max_length=200, truncation=True, padding='max_length', return_tensors='pt')\n","            yield source['input_ids'], target['input_ids']\n","\n","    def to_tensor(self, source_ids, target_ids):\n","        source_ids = torch.cat(source_ids, dim=0)\n","        target_ids = torch.cat(target_ids, dim=0)\n","        data = TensorDataset(source_ids, target_ids)\n","        return random_split(data, [len(data), 0])[0]\n","\n","    def prepare_data(self):\n","        source_ids, target_ids = list(\n","            zip(*tuple(self.encode_text('train_ds.json'))))\n","        self.train_ds = self.to_tensor(source_ids, target_ids)\n","\n","        source_ids, target_ids = list(\n","            zip(*tuple(self.encode_text('test_ds.json'))))\n","        self.test_ds = self.to_tensor(source_ids, target_ids)\n","\n","    def forward(self, batch, batch_idx):\n","        source_ids, target_ids = batch[:2]\n","        return self.model(input_ids=source_ids, labels=target_ids)\n","\n","    def training_step(self, batch, batch_idx):\n","        loss = self(batch, batch_idx)[0]\n","        self.log('train_loss', loss)\n","        return loss\n","\n","\n","    def validation_step(self, batch, batch_idx):\n","        loss = self(batch, batch_idx)[0]\n","        self.log('val_loss', loss)\n","\n","    def train_dataloader(self):\n","        return torch.utils.data.DataLoader(self.train_ds, batch_size=self.batch_size, drop_last=True, shuffle=True, num_workers=0)\n","\n","    def val_dataloader(self):\n","        return torch.utils.data.DataLoader(self.test_ds, batch_size=self.batch_size, drop_last=False, shuffle=False, num_workers=0)\n","\n","    def configure_optimizers(self):\n","        return AdamW(self.parameters(), lr=self.lr, weight_decay=0.01)\n","\n","\n","# class SaveCallback(Callback):\n","#     def on_epoch_start(self, trainer, pl_module):\n","#         if pl_module.current_epoch > 0:\n","#             current_epoch = str(pl_module.current_epoch)\n","#             fn = f'epoch_{current_epoch}'\n","#             new_path = f\"{save_path}/{fn}/\"\n","#             if fn not in os.listdir(save_path):\n","#                 os.mkdir(new_path)\n","#             pl_module.tokenizer.save_vocabulary(new_path)\n","#             pl_module.model.save_pretrained(new_path)"],"metadata":{"id":"3XVjVLJhKsV3","executionInfo":{"status":"ok","timestamp":1708214198856,"user_tz":-60,"elapsed":290,"user":{"displayName":"Jaromír Salamon","userId":"07277902595109530723"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["trainer = pl.Trainer(\n","    default_root_dir='logs',\n","    min_epochs=4,\n","    accelerator='gpu',\n","    max_epochs=5,\n","    val_check_interval=0.5,\n","    # callbacks=[SaveCallback()],\n","    logger=pl.loggers.TensorBoardLogger('logs/', name='paraphrase', version=0)\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U_-SrKqgYtxV","executionInfo":{"status":"ok","timestamp":1708214204875,"user_tz":-60,"elapsed":335,"user":{"displayName":"Jaromír Salamon","userId":"07277902595109530723"}},"outputId":"4860a9d6-82d5-4041-9f3f-ca4397c58e62"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"]}]},{"cell_type":"code","source":["para_model = ParaphraseGenerator(model_name)\n","trainer.fit(para_model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":456},"id":"XK7y0uleYvi9","executionInfo":{"status":"error","timestamp":1708214210786,"user_tz":-60,"elapsed":3291,"user":{"displayName":"Jaromír Salamon","userId":"07277902595109530723"}},"outputId":"2db323ce-ed54-4caf-e07e-f1d47bfb28fc"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["train_ds.json\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5_fast.py:160: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n","For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n","- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n","- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n","- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n","  warnings.warn(\n"]},{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'train_ds.json'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-81b4d3510080>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpara_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParaphraseGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpara_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainerStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRUNNING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m         call._call_and_handle_interrupt(\n\u001b[0m\u001b[1;32m    544\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_TunerExitException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mmodel_connected\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         )\n\u001b[0;32m--> 579\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.__class__.__name__}: preparing data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 946\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_connector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m         \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_setup_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# allow user to set up LightningModule in accelerator environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py\u001b[0m in \u001b[0;36mprepare_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mlm_prepare_data_per_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlightning_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_data_per_node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlm_prepare_data_per_node\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlocal_rank_zero\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mlm_prepare_data_per_node\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mglobal_rank_zero\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                 \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_lightning_module_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"prepare_data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     def attach_data(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_lightning_module_hook\u001b[0;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[LightningModule]{pl_module.__class__.__name__}.{hook_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;31m# restore current_fx when nested context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-19-312b95bc3821>\u001b[0m in \u001b[0;36mprepare_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         source_ids, target_ids = list(\n\u001b[0;32m---> 30\u001b[0;31m             zip(*tuple(self.encode_text('train_ds.json'))))\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-19-312b95bc3821>\u001b[0m in \u001b[0;36mencode_text\u001b[0;34m(self, data_path)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mencode_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train_ds.json'"]}]}]}