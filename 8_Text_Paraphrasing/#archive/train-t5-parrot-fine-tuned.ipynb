{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyP31JvzwuRSn3im5kDtiqiS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"2143895b9103474eaae2262eba54a29f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ef8325d2b4174bcdad856df9d3f32614","IPY_MODEL_b8db64bdeef14a3388bc4eaee7d49e8a","IPY_MODEL_a86d2143e5f64850bdc6283f91b69e32"],"layout":"IPY_MODEL_34dca43e8b834f98a70eb45b049f5f90"}},"ef8325d2b4174bcdad856df9d3f32614":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0f9fe32b418e4f25a7cba82db8ab24e6","placeholder":"​","style":"IPY_MODEL_2aa194edd6934eea8dcb187199818f70","value":"Map: 100%"}},"b8db64bdeef14a3388bc4eaee7d49e8a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d4e6814507e24858b0bb7a43a4618d27","max":212,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3af73e173f524e2aa5ce191192ea99ab","value":212}},"a86d2143e5f64850bdc6283f91b69e32":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_332485a32bdf4228aa65f9bbab6aa10c","placeholder":"​","style":"IPY_MODEL_03c2da680bfe4576bd40cd0a2dd4cd59","value":" 212/212 [00:00&lt;00:00, 1319.69 examples/s]"}},"34dca43e8b834f98a70eb45b049f5f90":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f9fe32b418e4f25a7cba82db8ab24e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2aa194edd6934eea8dcb187199818f70":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d4e6814507e24858b0bb7a43a4618d27":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3af73e173f524e2aa5ce191192ea99ab":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"332485a32bdf4228aa65f9bbab6aa10c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"03c2da680bfe4576bd40cd0a2dd4cd59":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["!pip install -q --upgrade transformers torch accelerate"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wgNlN91Agpv2","executionInfo":{"status":"ok","timestamp":1708343365081,"user_tz":-60,"elapsed":198890,"user":{"displayName":"Jaromír Salamon","userId":"07277902595109530723"}},"outputId":"57d13694-37c3-44af-a0d4-57d9e199b94d"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.0/280.0 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchaudio 2.1.0+cu121 requires torch==2.1.0, but you have torch 2.2.0 which is incompatible.\n","torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.2.0 which is incompatible.\n","torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.2.0 which is incompatible.\n","torchvision 0.16.0+cu121 requires torch==2.1.0, but you have torch 2.2.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["!pip uninstall pyarrow -y\n","!pip install -q pyarrow==12.0.0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0qEvMO5hwmTr","executionInfo":{"status":"ok","timestamp":1708343396461,"user_tz":-60,"elapsed":21809,"user":{"displayName":"Jaromír Salamon","userId":"07277902595109530723"}},"outputId":"b164f0de-2056-4975-804f-38101bbd9aa9"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: pyarrow 10.0.1\n","Uninstalling pyarrow-10.0.1:\n","  Successfully uninstalled pyarrow-10.0.1\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.9/38.9 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["import pyarrow\n","print(pyarrow.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rJgsC5Jawsnr","executionInfo":{"status":"ok","timestamp":1708343594714,"user_tz":-60,"elapsed":270,"user":{"displayName":"Jaromír Salamon","userId":"07277902595109530723"}},"outputId":"29a4c90e-d9ad-4fbe-c998-f5db1139499e"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["12.0.0\n"]}]},{"cell_type":"code","source":["!pip install -q datasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p-GKxppCwYws","executionInfo":{"status":"ok","timestamp":1708343605067,"user_tz":-60,"elapsed":6722,"user":{"displayName":"Jaromír Salamon","userId":"07277902595109530723"}},"outputId":"8adbca81-b9a5-44ff-d1a7-6cf116d871dd"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.7/536.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["import accelerate\n","print(accelerate.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BmqHff1J9Wiv","executionInfo":{"status":"ok","timestamp":1708343615710,"user_tz":-60,"elapsed":7496,"user":{"displayName":"Jaromír Salamon","userId":"07277902595109530723"}},"outputId":"b4d4ba11-8f48-400f-a7d4-ef69846dad06"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["0.27.2\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"llDC6DpU0vwf","executionInfo":{"status":"ok","timestamp":1708343636789,"user_tz":-60,"elapsed":18794,"user":{"displayName":"Jaromír Salamon","userId":"07277902595109530723"}},"outputId":"255b56c2-fde5-41e9-af62-60b80b0f0fd6"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["ds = 'manual' # 'mrpc','manual'\n","\n","input_path = '/content/drive/My Drive/Colab Notebooks/5_Corpora/corpora/'\n","pretrained_path = '/content/drive/My Drive/Colab Notebooks/8_Text_Paraphrasing/pretrained/parrot'\n","file_path = f'{ds}-triplet-corpus.csv'"],"metadata":{"id":"UjBApU5U1dY6","executionInfo":{"status":"ok","timestamp":1708343744972,"user_tz":-60,"elapsed":318,"user":{"displayName":"Jaromír Salamon","userId":"07277902595109530723"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["from transformers import T5Tokenizer, T5ForConditionalGeneration, Seq2SeqTrainingArguments, Seq2SeqTrainer\n","from datasets import Dataset\n","import torch\n","import pandas as pd"],"metadata":{"id":"N9TW1OANzPqk","executionInfo":{"status":"ok","timestamp":1708343778609,"user_tz":-60,"elapsed":417,"user":{"displayName":"Jaromír Salamon","userId":"07277902595109530723"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","execution_count":14,"metadata":{"id":"9gY5MTH4u5jN","executionInfo":{"status":"ok","timestamp":1708343781014,"user_tz":-60,"elapsed":2,"user":{"displayName":"Jaromír Salamon","userId":"07277902595109530723"}}},"outputs":[],"source":["def preprocess_data(examples, tokenizer):\n","    inputs = [\"paraphrase: \" + doc for doc in examples[\"input_text\"]]\n","    model_inputs = tokenizer(inputs, max_length=512, truncation=True, padding=\"max_length\")\n","\n","    # Setup the tokenizer for targets\n","    labels = tokenizer(examples[\"target_text\"], max_length=512, truncation=True, padding=\"max_length\")\n","\n","    model_inputs[\"labels\"] = labels[\"input_ids\"]\n","    return model_inputs"]},{"cell_type":"code","source":["def fine_tune_parrot_model(dataset_path, output_dir):\n","    # Load the tokenizer and model specifically tailored for paraphrasing\n","    tokenizer = T5Tokenizer.from_pretrained('prithivida/parrot_paraphraser_on_T5')\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model = T5ForConditionalGeneration.from_pretrained('prithivida/parrot_paraphraser_on_T5')\n","    model.to(device)\n","\n","    # Load the dataset\n","    df = pd.read_csv(dataset_path)\n","    dataset = df[['original', 'positive']].rename(columns={'original': 'input_text', 'positive': 'target_text'}) # Adjust based on sentiment\n","    dataset = Dataset.from_pandas(dataset)\n","\n","    # Preprocess the dataset\n","    tokenized_dataset = dataset.map(lambda x: preprocess_data(x, tokenizer), batched=True)\n","\n","    # Training arguments\n","    training_args = Seq2SeqTrainingArguments(\n","        output_dir=output_dir,\n","        per_device_train_batch_size=4,\n","        per_device_eval_batch_size=4,\n","        predict_with_generate=True,\n","        evaluation_strategy=\"epoch\",\n","        save_strategy=\"epoch\",\n","        num_train_epochs=3,\n","        weight_decay=0.01,\n","    )\n","\n","    # Initialize the trainer\n","    trainer = Seq2SeqTrainer(\n","        model=model,\n","        args=training_args,\n","        train_dataset=tokenized_dataset,\n","        eval_dataset=tokenized_dataset, # Assuming you want to use the same dataset for simplicity; adjust as needed\n","        tokenizer=tokenizer,\n","    )\n","\n","    # Train the model\n","    trainer.train()\n","\n","    # Save the fine-tuned model and tokenizer\n","    # model.save_pretrained(output_dir)\n","    # tokenizer.save_pretrained(output_dir)\n","\n","    return model, tokenizer"],"metadata":{"id":"4vSDN7xZzaoW","executionInfo":{"status":"ok","timestamp":1708343783014,"user_tz":-60,"elapsed":435,"user":{"displayName":"Jaromír Salamon","userId":"07277902595109530723"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# Given that `prithivida/parrot_paraphraser_on_T5` is already fine-tuned for paraphrasing, you may not need to fine-tune further for similar tasks\n","# However, if you have a specific dataset or wish to further tailor the model, you can proceed with training as demonstrated earlier\n","\n","model, tokenizer = fine_tune_parrot_model(folder_input_path + csv_file_path, folder_pretrained_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":275,"referenced_widgets":["2143895b9103474eaae2262eba54a29f","ef8325d2b4174bcdad856df9d3f32614","b8db64bdeef14a3388bc4eaee7d49e8a","a86d2143e5f64850bdc6283f91b69e32","34dca43e8b834f98a70eb45b049f5f90","0f9fe32b418e4f25a7cba82db8ab24e6","2aa194edd6934eea8dcb187199818f70","d4e6814507e24858b0bb7a43a4618d27","3af73e173f524e2aa5ce191192ea99ab","332485a32bdf4228aa65f9bbab6aa10c","03c2da680bfe4576bd40cd0a2dd4cd59"]},"id":"l7saL5IcxjSC","executionInfo":{"status":"ok","timestamp":1708345593540,"user_tz":-60,"elapsed":303034,"user":{"displayName":"Jaromír Salamon","userId":"07277902595109530723"}},"outputId":"801ab467-45d5-451c-8b31-566d54672d77"},"execution_count":30,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/212 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2143895b9103474eaae2262eba54a29f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='159' max='159' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [159/159 04:59, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.086402</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.075281</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>No log</td>\n","      <td>0.067671</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Checkpoint destination directory /content/drive/My Drive/Colab Notebooks/8_Text_Paraphrasing/pretrained/parrot/checkpoint-53 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n","Checkpoint destination directory /content/drive/My Drive/Colab Notebooks/8_Text_Paraphrasing/pretrained/parrot/checkpoint-106 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n","Checkpoint destination directory /content/drive/My Drive/Colab Notebooks/8_Text_Paraphrasing/pretrained/parrot/checkpoint-159 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"]}]},{"cell_type":"code","source":["# Reminder: This example is structured for demonstrating how to load and potentially fine-tune a specific paraphrasing model\n","# For actual paraphrasing (inference), use the model's `generate` function with appropriate parameters"],"metadata":{"id":"h3uDiWyM0jZd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Ensure model is in evaluation mode\n","# model.eval()\n","\n","# Move model to the appropriate device (GPU or CPU)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","model.to(device)\n","\n","# Prepare your input text\n","input_text = \"This is the sentence I want to paraphrase.\"\n","input_text = \"paraphrase: \" + input_text  # Add any necessary prefix\n","input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n","print(input_ids)\n","\n","# Generate the paraphrase\n","outputs = model.generate(input_ids, max_length=50, num_beams=5, early_stopping=True)\n","print(outputs)\n","\n","# Decode generated text\n","generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","print(f\"Generated text: {generated_text}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jTzXKl6UhCnk","executionInfo":{"status":"ok","timestamp":1708345612015,"user_tz":-60,"elapsed":2153,"user":{"displayName":"Jaromír Salamon","userId":"07277902595109530723"}},"outputId":"8062cbcf-f513-4250-883a-69c4c7b770ae"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n","tensor([[ 3856, 27111,    10,   100,    19,     8,  7142,    27,   241,    12,\n","          3856, 27111,     5,     1]], device='cuda:0')\n","tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0]], device='cuda:0')\n","Generated text: \n"]}]},{"cell_type":"code","source":["from transformers import T5ForConditionalGeneration, T5Tokenizer\n","\n","# model_name = \"t5-small\"  # or any other T5 variant\n","model_name = \"prithivida/parrot_paraphraser_on_T5\"\n","tokenizer = T5Tokenizer.from_pretrained(model_name)\n","model = T5ForConditionalGeneration.from_pretrained(model_name)\n","\n","model.eval()\n","model.to(device)\n","print(device)\n","\n","input_text = \"paraphrase: This is the sentence I want to paraphrase.\"\n","input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n","print(input_ids)\n","\n","attention_mask = torch.ones_like(input_ids)\n","outputs = model.generate(input_ids, attention_mask=attention_mask, max_length=50)\n","# outputs = model.generate(input_ids, max_length=50)\n","# outputs = model.generate(input_ids, max_length=50, early_stopping=False, num_beams=1)\n","generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","print(f\"Generated text with pretrained model: {generated_text}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"crMngrwsSGcO","executionInfo":{"status":"ok","timestamp":1708344995659,"user_tz":-60,"elapsed":3301,"user":{"displayName":"Jaromír Salamon","userId":"07277902595109530723"}},"outputId":"156f5f4c-4eb3-4048-c79e-382a3023064f"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Generated text with pretrained model: This is the sentence I want to paraphrase.\n"]}]}]}